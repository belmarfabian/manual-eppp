# (PART) Aplicaciones {-}

# Casos de evaluación en Chile

Este capítulo presenta estudios de caso de evaluaciones de programas chilenos emblemáticos, ilustrando la aplicación práctica de las metodologías presentadas en capítulos anteriores. Cada caso muestra diseños evaluativos reales, hallazgos clave y lecciones aprendidas.

## Caso 1: Chile Crece Contigo - Evaluación de sistema integrado de protección a la infancia

### Contexto del programa

**Chile Crece Contigo** (ChCC) constituye el subsistema de protección integral a la primera infancia en Chile, operando desde 2007. Es uno de los sistemas más comprehensivos de América Latina, integrando prestaciones de salud, educación y protección social desde la gestación hasta el ingreso al sistema escolar (4 años de edad).

**Componentes principales**:

1. **Atención en salud**: Control prenatal, parto, controles de salud infantil, vacunación
2. **Educación parental**: Talleres de crianza, guías anticipatorias, visitas domiciliarias
3. **Prestaciones monetarias**: Subsidios complementarios para familias vulnerables
4. **Apoyo al desarrollo infantil**: Estimulación temprana, jardines infantiles, educación preescolar
5. **Prestaciones especiales**: Ayudas técnicas para niños con rezago en desarrollo

**Población objetivo**: Todos los niños y niñas desde gestación hasta 4 años, con prestaciones universales y focalizadas según vulnerabilidad.

**Presupuesto**: ~$250.000 millones anuales (2022)

### Teoría de cambio del programa

**Problema identificado**: Desigualdades tempranas en desarrollo infantil determinan brechas posteriores en trayectorias educativas y laborales.

**Supuestos del programa**:

1. **Ventana crítica**: Los primeros 1,000 días (gestación a 2 años) son fundamentales para desarrollo cerebral
2. **Integralidad**: Múltiples dimensiones (salud, nutrición, estimulación, protección) deben abordarse simultáneamente
3. **Universalidad con focalización**: Acceso universal asegura no estigmatización; prestaciones focalizadas abordan brechas específicas
4. **Intersectorialidad**: Coordinación entre salud, educación y protección social maximiza efectividad

**Cadena causal esperada**:

Gestación saludable → Parto seguro → Controles de salud → Detección oportuna de rezagos → Estimulación temprana → Mejor desarrollo psicomotor y socioemocional → Ingreso exitoso a educación preescolar → Mejores trayectorias educativas

### Evaluaciones realizadas

#### A. Evaluación de diseño (2009)

**Metodología**: Análisis documental, entrevistas a diseñadores del programa, revisión de evidencia internacional

**Hallazgos**:

- **Fortaleza de diseño**: Modelo de gestión en red integra niveles nacional, regional y local
- **Coherencia con evidencia**: Componentes basados en literatura científica sobre desarrollo infantil
- **Desafío institucional**: Requiere articulación de 3 ministerios (Salud, Educación, Desarrollo Social) con tradición de trabajo sectorial
- **Riesgo identificado**: Variabilidad en implementación comunal por heterogeneidad de capacidades municipales

#### B. Evaluación de procesos (2012)

**Metodología**:
- Análisis de registros administrativos de 345 comunas
- Encuesta a 200 encargados comunales ChCC
- 50 entrevistas a directores de programas
- 20 grupos focales con beneficiarias
- Visitas a terreno en 15 comunas

**Hallazgos de cobertura**:

| Componente | Cobertura | Meta | Brecha |
|------------|-----------|------|--------|
| Control prenatal | 99% | 95% | ✓ Superado |
| Control niño sano (0-4 años) | 92% | 90% | ✓ Cumplido |
| Visitas domiciliarias integrales | 58% | 80% | ✗ Brecha |
| Talleres de habilidades parentales | 35% | 60% | ✗ Brecha significativa |
| Sala cuna y jardines infantiles | 48% | 70% | ✗ Brecha |

**Hallazgos de calidad**:
- **Componente salud**: Alta fidelidad de implementación (98% de consultorios aplica protocolos)
- **Componente educación**: Implementación heterogénea (45% de comunas no ofrece talleres parentales)
- **Satisfacción de usuarias**: 78% evalúa positivamente atención recibida

**Factores explicativos de variabilidad**:
- **Compromiso político local**: Comunas con alcaldes comprometidos tienen 40% más cobertura en componentes no obligatorios
- **Capacidad técnica**: Comunas con profesionales especializados (psicólogos, educadores) logran 35% más fidelidad
- **Recursos municipales**: Comunas con mayor presupuesto per cápita tienen mejor infraestructura

**Eficiencia**:
- Costo promedio: $120,000 por niño atendido anualmente
- Variabilidad: $80,000 (comunas grandes) a $200,000 (comunas rurales pequeñas)
- **Hallazgo**: Deseconomías de escala en territorios con población dispersa

#### C. Evaluación de resultados (2014)

**Metodología**: Encuesta longitudinal a 5,000 familias beneficiarias, mediciones en gestación, 12 meses y 24 meses

**Indicadores de resultado**:

**1. Desarrollo psicomotor (Test de Desarrollo Psicomotor TEPSI a 24 meses)**

| Grupo | Normal | Riesgo | Retraso |
|-------|--------|--------|---------|
| Beneficiarios ChCC (60% más vulnerable) | 72% | 20% | 8% |
| No beneficiarios (40% menos vulnerable) | 85% | 12% | 3% |

**Hallazgo**: ChCC reduce brecha de desarrollo entre grupos socioeconómicos en 40% comparado con escenario sin programa

**2. Lactancia materna exclusiva hasta 6 meses**
- Beneficiarias ChCC: 58%
- Promedio nacional pre-ChCC (2005): 43%
- **Efecto**: +15 puntos porcentuales

**3. Cumplimiento de controles de salud**
- ChCC: 92% de niños con controles al día
- Pre-ChCC (2006): 78%
- **Efecto**: +14 puntos porcentuales

**4. Detección oportuna de rezagos**
- % de niños con rezago detectado antes de 18 meses: 65% (vs 28% pre-ChCC)

#### D. Evaluación de impacto cuasi-experimental (2016)

**Pregunta evaluativa**: ¿ChCC causó mejoras en desarrollo infantil atribuibles al programa?

**Desafío metodológico**: ChCC es universal desde 2009, no permite comparación simple tratados/control

**Estrategia de identificación**: **Diferencias en Diferencias** explotando rollout gradual

**Diseño**:
- **Grupo tratamiento temprano**: Cohortes nacidas 2008-2009 (ChCC implementado)
- **Grupo tratamiento tardío** (control temporal): Cohortes nacidas 2005-2006 (pre-ChCC)
- **Medición**: Test de desarrollo a los 30 meses en ambas cohortes
- **Comparación**: Cambio en desarrollo entre cohortes en comunas que implementaron ChCC vs comunas con implementación retrasada

**Datos**:
- Registros administrativos de controles de salud de 450,000 niños
- Test de desarrollo psicomotor ( TEPSI) aplicado en consultorios

**Estimación**:

```
Impacto DiD = [Desarrollo_2008-09 - Desarrollo_2005-06]_ChCC_temprano
              - [Desarrollo_2008-09 - Desarrollo_2005-06]_ChCC_tardío
```

**Resultados**:

| Dimensión de desarrollo | Impacto (puntos TEPSI) | Significancia |
|--------------------------|------------------------|---------------|
| **Desarrollo psicomotor total** | **+3.2 puntos** | p < 0.01 |
| Coordinación | +2.8 | p < 0.01 |
| Lenguaje | +4.1 | p < 0.001 |
| Motricidad | +2.3 | p < 0.05 |

**Interpretación**: ChCC causó un aumento de 3.2 puntos en test de desarrollo (equivalente a 0.18 desviaciones estándar), estadísticamente significativo.

**Heterogeneidad de impactos**:

- **Mayor impacto** en familias del 40% más vulnerable: +4.5 puntos
- **Menor impacto** en familias de ingresos medios: +1.8 puntos
- **Hipótesis**: Programa compensa desventajas iniciales de familias más vulnerables

**Robustez del diseño**:

- **Test de tendencias paralelas**: Cohortes 2004-2005 (ambas pre-ChCC) no muestran diferencias significativas → Validación del supuesto DiD
- **Análisis de sensibilidad**: Resultados robustos a diferentes especificaciones de controles

### Evaluación de sostenibilidad

**Institucionalización** (Alta):
- ChCC establecido por ley desde 2009 (Ley 20.379)
- Presupuesto permanente en Ministerio de Desarrollo Social
- Estructura de gobernanza intersectorial consolidada

**Apropiación territorial** (Media):
- 85% de comunas mantienen equipos ChCC estables
- 60% incorporó componentes a planificación comunal regular
- **Riesgo**: Dependencia de financiamiento central (municipios aportan <5%)

**Sostenibilidad técnica** (Alta):
- Formación de ~3,000 profesionales especializados en primera infancia
- Protocolos clínicos institucionalizados en red de salud pública

### Lecciones aprendidas del caso ChCC

#### Fortalezas del diseño evaluativo

1. **Múltiples evaluaciones complementarias**: Diseño → Procesos → Resultados → Impacto permite visión integral
2. **Aprovechamiento de rollout gradual**: Variación temporal generó oportunidad para evaluación cuasi-experimental
3. **Combinación métodos mixtos**: Cuantitativos (impacto) + cualitativos (procesos) explican qué funciona y por qué

#### Desafíos enfrentados

1. **Atribución causal compleja**: Múltiples componentes simultáneos dificultan identificar qué componente específico genera efectos
2. **Efectos de largo plazo**: Impactos en trayectorias educativas (objetivo final) requieren seguimiento 10-15 años
3. **Variabilidad territorial**: Implementación heterogénea complica generalización de resultados

#### Usos de la evaluación

1. **Rediseño operacional**: Evaluación de procesos llevó a fortalecer componentes débiles (educación parental)
2. **Reasignación de recursos**: Identificación de brechas territoriales orientó inversión adicional
3. **Escalamiento**: Evidencia de impacto justificó ampliación de cobertura (de 0-4 a 0-9 años en 2016)

## Caso 2: Subvención Escolar Preferencial (SEP) - Evaluación de incentivos en educación

### Contexto del programa

La **Ley de Subvención Escolar Preferencial** (2008) constituye una de las reformas educativas más importantes de Chile post-retorno a democracia. Entrega recursos adicionales a escuelas (públicas y privadas subvencionadas) por cada estudiante prioritario (60% más vulnerable) y preferente (siguiente 20% vulnerable) matriculado.

**Componente clave**: Recursos condicionados a suscripción de **Plan de Mejoramiento Educativo** (PME) con metas de aprendizaje.

**Monto de la subvención** (2022):
- Estudiante prioritario: $147,000 adicionales por alumno/año
- Estudiante preferente: $98,000 adicionales por alumno/año

**Cobertura**: ~1.2 millones de estudiantes prioritarios/preferentes en 9,500 escuelas

**Inversión anual**: ~$600,000 millones

### Teoría de cambio

**Problema**: Estudiantes vulnerables concentrados en escuelas de bajo rendimiento, perpetuando desigualdad educativa.

**Hipótesis de intervención**:

1. **Recursos adicionales** permiten a escuelas contratar profesores, reducir tamaño de cursos, adquirir materiales
2. **Incentivos por matrícula vulnerable** generan competencia por estudiantes prioritarios (antes evitados)
3. **Compromiso con metas** (PME) orienta recursos a mejoras pedagógicas

**Cadena causal esperada**:

Recursos SEP → Inversión en calidad (profesores, materiales, infraestructura) → Mejores prácticas pedagógicas → Mayor aprendizaje de estudiantes prioritarios → Reducción de brecha de rendimiento

**Supuestos críticos**:
- Escuelas tienen capacidad técnica para diseñar e implementar PME efectivos
- Recursos se usan en mejoras pedagógicas (no capturados por sostenedores)
- Rendición de cuentas (Superintendencia) asegura cumplimiento de compromisos

### Evaluaciones realizadas

#### A. Evaluación ex-ante de diseño (2008)

**Metodología**: Simulación de efectos de equilibrio general (modelo de elección escolar)

**Pregunta**: ¿Incentivos SEP modificarán comportamiento de escuelas y familias?

**Hallazgos de simulación**:

1. **Efecto en composición**: Modelo predice aumento de 5-8% en matrícula de estudiantes prioritarios en escuelas privadas subvencionadas (antes evitados por costos de selección)
2. **Riesgo de cream-skimming**: Escuelas podrían seleccionar prioritarios de "mejor rendimiento" dentro del grupo vulnerable
3. **Efectos redistributivos**: Transferencia de $300,000 millones anuales a escuelas que atienden vulnerabilidad

**Recomendaciones derivadas**:
- Prohibir cobros y selección a estudiantes prioritarios (incorporado en ley final)
- Supervisar uso de recursos mediante Superintendencia de Educación

#### B. Evaluación de procesos: Uso de recursos SEP (2012)

**Metodología**: Encuesta a 800 escuelas + análisis de 200 PME + visitas a 30 escuelas

**Pregunta**: ¿En qué invierten las escuelas los recursos SEP?

**Resultados**:

| Categoría de gasto | % del total SEP | Evaluación |
|--------------------|-----------------|------------|
| **Contratación de profesores y asistentes** | 45% | ✓ Uso prioritario |
| **Material didáctico y recursos de aprendizaje** | 18% | ✓ Pertinente |
| **Capacitación docente** | 12% | ✓ Pertinente |
| **Infraestructura menor** | 10% | Neutro |
| **Servicios de apoyo** (psicólogos, tutores) | 8% | ✓ Pertinente |
| **Gastos administrativos** | 7% | ⚠ Cuestionable |

**Hallazgo principal**: 75% de recursos se invierte en áreas pedagógicamente pertinentes.

**Variabilidad por dependencia**:
- Escuelas municipales: Mayor gasto en personal (55%) y menor en capacitación (8%)
- Escuelas particulares subvencionadas: Mayor gasto en capacitación (16%) y materiales (22%)

**Calidad de los PME**:
- Solo 35% de PME incluye metas específicas y medibles
- 48% de escuelas no realiza seguimiento trimestral de PME
- **Brecha identificada**: Débil capacidad técnica de escuelas para planificación estratégica

#### C. Evaluación de resultados: Cumplimiento de metas PME (2013)

**Metodología**: Análisis de 5,000 PME y resultados SIMCE 2011-2013

**Pregunta**: ¿Las escuelas SEP cumplen las metas de aprendizaje comprometidas en PME?

**Resultados**:

| Nivel de cumplimiento | % de escuelas |
|-----------------------|---------------|
| Cumplimiento total (>90% de metas) | 28% |
| Cumplimiento parcial (50-89% de metas) | 45% |
| Bajo cumplimiento (<50% de metas) | 27% |

**Factores asociados a cumplimiento**:

- **Calidad técnica del PME** (explicar 35% de varianza): Escuelas con PME específicos y focalizados cumplen 40% más metas
- **Acompañamiento externo**: Escuelas con asesoría técnica (ATE) cumplen 25% más que escuelas sin apoyo
- **Tamaño de escuela**: Escuelas grandes (>500 alumnos) cumplen 15% más que escuelas pequeñas

#### D. Evaluación de impacto cuasi-experimental en aprendizajes (2014-2015)

**Pregunta central**: ¿SEP causó mejoras en rendimiento académico de estudiantes prioritarios?

**Desafío metodológico**: SEP es universal en escuelas que lo suscriben (no hay aleatorización)

**Estrategia de identificación**: **Diferencias en Diferencias** explotando timing de incorporación

**Diseño**:
- **Tratados tempranos**: Escuelas que ingresaron a SEP en 2008 (1° año)
- **Tratados tardíos** (control temporal): Escuelas que ingresaron en 2011-2012
- **Período**: 2006 (pre-SEP) a 2013
- **Datos**: Resultados SIMCE 4° básico de 5,000 escuelas

**Especificación del modelo**:

```
SIMCE_it = β₀ + β₁·SEP_it + β₂·X_it + μ_i + λ_t + ε_it

Donde:
- SIMCE_it: Puntaje escuela i en año t
- SEP_it: Indicador de participación en SEP
- X_it: Controles (matrícula, NSE, ruralidad)
- μ_i: Efectos fijos de escuela
- λ_t: Efectos fijos de año
- β₁: Impacto causal de SEP
```

**Resultados de impacto**:

| Asignatura | Impacto (puntos SIMCE) | Equivalente | Significancia |
|------------|------------------------|-------------|---------------|
| **Matemáticas** | **+6.2 puntos** | 0.15 DE | p < 0.01 |
| **Lenguaje** | **+4.8 puntos** | 0.12 DE | p < 0.01 |
| **Ciencias Naturales** | +3.5 puntos | 0.09 DE | p < 0.05 |

**Interpretación**: SEP causó aumentos moderados pero significativos en aprendizajes, equivalentes a 3-4 meses adicionales de escolaridad.

**Análisis de heterogeneidad**:

**Por nivel socioeconómico de escuela**:
- Escuelas 40% más vulnerable: +8.5 puntos en Matemáticas
- Escuelas vulnerabilidad media: +4.2 puntos
- **Hallazgo**: Mayor impacto donde mayor concentración de pobreza

**Por dependencia administrativa**:
- Escuelas municipales: +5.8 puntos
- Escuelas particulares subvencionadas: +6.5 puntos
- **Hallazgo**: Efectos similares entre sectores

**Por tamaño de escuela**:
- Escuelas rurales pequeñas (<100 alumnos): +9.2 puntos
- Escuelas urbanas grandes: +4.5 puntos
- **Hipótesis**: Escuelas pequeñas usan recursos de manera más focalizada

**Test de robustez**:

1. **Tendencias paralelas**: Verificación de evolución SIMCE 2004-2007 (pre-SEP) muestra tendencias similares entre tratados tempranos y tardíos → Supuesto DiD validado
2. **Placebo**: No se observan efectos en escuelas que no recibieron SEP
3. **Variables instrumentales**: Uso de elegibilidad administrativa como instrumento confirma resultados

### Evaluación de eficiencia y costo-efectividad (2016)

**Pregunta**: ¿SEP es costo-efectiva comparada con otras intervenciones educativas?

**Cálculo de costo-efectividad**:

- **Costo**: $147,000 por estudiante prioritario/año
- **Efecto**: +6.2 puntos SIMCE en Matemáticas
- **Costo-efectividad**: $23,700 por punto SIMCE

**Comparación con alternativas**:

| Intervención | Costo por punto SIMCE | Evaluación |
|--------------|----------------------|------------|
| SEP | $23,700 | Referencia |
| Reducción tamaño de curso (de 35 a 25) | $45,000 | Menos costo-efectiva |
| Programa de tutorías individualizadas | $18,000 | Más costo-efectiva |
| Jornada Escolar Completa | $35,000 | Menos costo-efectiva |

**Hallazgo**: SEP tiene costo-efectividad intermedia, mejor que intervenciones masivas (JEC) pero inferior a intervenciones muy focalizadas (tutorías).

### Evaluación de efectos no intencionados (2017)

**Pregunta**: ¿SEP generó efectos perversos no anticipados?

**Efectos analizados**:

**1. Selección de estudiantes prioritarios**
- **Hipótesis**: Escuelas podrían seleccionar prioritarios de mejor rendimiento
- **Evidencia**: No se detecta aumento en selección encubierta (test de distribución de habilidades de prioritarios)

**2. Reclasificación estratégica**
- **Hipótesis**: Escuelas podrían manipular clasificación de estudiantes como prioritarios
- **Evidencia**: <2% de casos sospechosos (control del Registro Social de Hogares limita manipulación)

**3. Efectos en estudiantes no prioritarios**
- **Hipótesis**: Recursos focalizados en prioritarios podrían desatender a no prioritarios
- **Evidencia**: No se observa reducción de rendimiento en no prioritarios (efecto neutro)

**4. Segregación entre escuelas**
- **Hipótesis**: SEP podría aumentar segregación si escuelas privadas atraen prioritarios de mejor nivel
- **Evidencia**: Leve reducción de segregación (-3% en índice de disimilitud Duncan) por prohibición de selección

### Lecciones aprendidas del caso SEP

#### Fortalezas del diseño del programa

1. **Incentivos bien calibrados**: Monto suficiente para generar cambios sin crear dependencia
2. **Prohibición de selección**: Evitó cream-skimming y redujo segregación
3. **Flexibilidad en uso de recursos**: Escuelas priorizan según contexto

#### Debilidades identificadas

1. **Capacidad técnica heterogénea**: Muchas escuelas no saben diseñar PME efectivos
2. **Supervisión débil**: Superintendencia no sanciona incumplimiento de metas
3. **Horizontetemporalista**: Presión por resultados anuales desincentiva inversiones de largo plazo (ej: formación docente)

#### Efectividad de la estrategia evaluativa

1. **DiD aprovechó variación temporal**: Rollout gradual permitió evaluación causal sin experimento
2. **Múltiples dimensiones evaluadas**: Desde uso de recursos hasta aprendizajes
3. **Análisis de heterogeneidad**: Identificó para quiénes funciona mejor

#### Usos de la evidencia

1. **Reformas al programa**: Evaluación llevó a mejorar acompañamiento técnico a escuelas
2. **Expansión de cobertura**: Evidencia de impacto justificó ampliación a estudiantes preferentes (2011)
3. **Debate público informado**: Resultados usados en discusión de reforma educacional 2015

## Caso 3: Ingreso Ético Familiar - Evaluación de programa multidimensional anti-pobreza

### Contexto del programa

El **Ingreso Ético Familiar** (IEF, 2012-2018) fue un programa emblemático del segundo gobierno de Sebastián Piñera, diseñado como estrategia integral para superar pobreza extrema. Reemplazó y amplió el Programa Puente (2002-2011).

**Componentes**:

1. **Bono al Trabajo de la Mujer**: Subsidio al ingreso laboral de mujeres (hasta $60,000/mes)
2. **Bono por Hijo**: $13,500 mensuales por hijo
3. **Bono de Protección**: Transferencia base de $25,000 para familias extremadamente pobres
4. **Acompañamiento psicosocial**: Apoyo familiar personalizado (similar a Puente)
5. **Acceso preferente**: Prioridad en programas de vivienda, salud, educación

**Población objetivo**: 170,000 familias en situación de pobreza extrema

**Inversión**: ~$180,000 millones anuales

### Objetivos del programa

**Objetivo general**: Erradicar pobreza extrema en Chile al 2018

**Objetivos específicos**:
1. Aumentar ingresos monetarios de familias
2. Incrementar inserción laboral femenina
3. Mejorar acceso a prestaciones sociales
4. Fortalecer autonomía y organización familiar

### Teoría de cambio

**Diagnóstico**: Pobreza extrema es multidimensional - requiere simultáneamente:
- Ingresos monetarios
- Activación laboral (especialmente mujeres)
- Acceso a servicios sociales
- Fortalecimiento de capacidades familiares

**Hipótesis central**: **Sinergia** entre transferencias monetarias + incentivos laborales + acompañamiento psicosocial genera salida sostenible de pobreza.

**Mecanismo causal esperado**:

Bono Trabajo Mujer → Incentivo a trabajar → Ingreso laboral femenino → Mayor ingreso familiar → Salida de pobreza

+

Acompañamiento → Organización familiar → Acceso a servicios → Mejora en dimensiones no monetarias → Bienestar sostenible

### Evaluación de impacto: Diseño y metodología

#### Pregunta evaluativa central

¿El IEF causó aumento en ingresos y empleo femenino atribuibles al programa?

#### Desafío metodológico

- No hubo aleatorización (programa no experimental)
- Familias beneficiarias son extremadamente pobres (sesgo de selección observable y no observable)
- Rollout rápido (toda población elegible recibió programa en 2012-2013)

#### Estrategia de identificación: Propensity Score Matching (PSM)

**Supuesto**: Selección en observables - Todas las diferencias relevantes entre beneficiarios y no beneficiarios son capturadas por características observables.

**Paso 1: Estimación del Propensity Score**

Probabilidad de participar en IEF en función de características pre-programa:

```
P(IEF=1 | X) = Logit(α₀ + α₁·Ingreso₀ + α₂·Jefa_mujer + α₃·Años_escolaridad
                    + α₄·N_hijos + α₅·Ruralidad + α₆·Región + ...)
```

**Variables incluidas en el modelo**:
- Ingreso per cápita familiar 2011 (pre-programa)
- Composición del hogar (N° de niños, adultos mayores, jefatura femenina)
- Escolaridad de jefa de hogar
- Situación laboral 2011
- Acceso a servicios (salud, vivienda)
- Territorio (región, ruralidad)

**Datos**: Encuesta CASEN 2011 (pre-programa) y 2013 (post-programa)

**Muestra**:
- Tratados: 15,000 hogares IEF
- Pool de controles potenciales: 45,000 hogares pobres no-IEF

**Paso 2: Matching**

Cada hogar IEF fue emparejado con hogar no-IEF de propensity score similar:

- **Método**: Nearest neighbor matching (1:1) con caliper de 0.01
- **Balance**: Test de diferencias en medias pre-programa entre tratados y matched controls

**Validación del matching**:

| Variable | Tratados (IEF) | Controles matched | Diferencia | p-value |
|----------|---------------|-------------------|------------|---------|
| Ingreso per cápita 2011 | $45,200 | $44,800 | -$400 | 0.62 (NS) |
| % Jefatura femenina | 68% | 66% | +2pp | 0.31 (NS) |
| Años escolaridad jefa | 7.2 | 7.1 | +0.1 | 0.74 (NS) |
| % Ruralidad | 22% | 23% | -1pp | 0.68 (NS) |

**Resultado**: Grupos balanceados en observables → Matching exitoso

**Paso 3: Estimación de impacto**

Comparación de resultados 2013 entre tratados IEF y controles matched:

```
Impacto = E[Y₂₀₁₃ | IEF=1, X] - E[Y₂₀₁₃ | IEF=0, X]
```

### Resultados de la evaluación de impacto

#### Impacto en ingresos familiares

| Indicador | IEF (2013) | Control (2013) | Impacto | % cambio |
|-----------|------------|----------------|---------|----------|
| **Ingreso per cápita** | **$72,300** | **$58,400** | **+$13,900** | **+24%** |
| Ingresos del trabajo | $48,500 | $42,200 | +$6,300 | +15% |
| Transferencias monetarias | $23,800 | $16,200 | +$7,600 | +47% |

**Interpretación**: IEF aumentó ingreso per cápita en $13,900 mensuales (+24%), combinando aumento en ingreso laboral (+$6,300) y transferencias (+$7,600).

#### Impacto en empleo femenino

| Indicador | IEF | Control | Impacto | Significancia |
|-----------|-----|---------|---------|---------------|
| **Tasa de ocupación mujeres** | **42%** | **35%** | **+7 pp** | p < 0.01 |
| Horas trabajadas (ocupadas) | 38.5 hrs | 36.2 hrs | +2.3 hrs | p < 0.05 |
| Ingreso laboral mujeres | $185,000 | $165,000 | +$20,000 | p < 0.01 |

**Interpretación**: IEF aumentó participación laboral femenina en 7 puntos porcentuales, con efectos también en horas trabajadas e ingresos laborales.

**Mecanismo**: Bono al Trabajo de la Mujer incentivó entrada al mercado laboral al complementar (no sustituir) ingreso laboral.

#### Impacto en pobreza

| Indicador | IEF | Control | Impacto |
|-----------|-----|---------|---------|
| % en pobreza extrema (ingreso) | 12% | 28% | **-16 pp** |
| % en pobreza total | 38% | 52% | **-14 pp** |

**Interpretación**: IEF redujo pobreza extrema en 16 puntos porcentuales (de 28% a 12%).

#### Impacto en dimensiones no monetarias

| Dimensión | IEF | Control | Impacto |
|-----------|-----|---------|---------|
| Acceso a atención de salud oportuna | 78% | 68% | +10 pp |
| Niños con controles de salud al día | 85% | 74% | +11 pp |
| Asistencia escolar regular (6-17 años) | 94% | 91% | +3 pp |

**Interpretación**: Efectos positivos en acceso a servicios, aunque menores que efectos monetarios.

### Análisis de heterogeneidad de impactos

#### Por composición del hogar

| Tipo de hogar | Impacto en ingreso | Impacto en empleo femenino |
|---------------|-------------------|---------------------------|
| Jefatura femenina sin pareja | +$16,200 | +12 pp |
| Jefatura femenina con pareja | +$12,800 | +5 pp |
| Jefatura masculina | +$11,500 | +3 pp |

**Hallazgo**: Mayor impacto en hogares monoparentales con jefa mujer (población más vulnerable).

#### Por territorio

| Zona | Impacto en ingreso | Impacto en empleo femenino |
|------|-------------------|---------------------------|
| Urbana | +$12,500 | +8 pp |
| Rural | +$17,200 | +4 pp |

**Hallazgo**: Mayor impacto monetario en zonas rurales (donde ingresos bajos), pero mayor impacto laboral en zonas urbanas (mayor oferta de empleo).

### Evaluación de sostenibilidad: ¿Efectos persisten post-programa?

**Pregunta**: ¿Familias que egresan de IEF mantienen mejoras en ingresos?

**Metodología**: Seguimiento a 2,000 familias que egresaron del programa en 2015-2016, mediciones en 2017 (1 año post-egreso)

**Resultados**:

| Indicador | Familias egresadas IEF (2017) | Control | Diferencia |
|-----------|------------------------------|---------|------------|
| Tasa de pobreza extrema | 18% | 28% | -10 pp |
| Empleo femenino | 38% | 35% | +3 pp |

**Interpretación**:

- **Sostenibilidad parcial**: Efectos del programa persisten 1 año post-egreso, pero se reducen (de -16pp a -10pp en pobreza extrema)
- **Empleo femenino más sostenible**: Efecto laboral se mantiene (de +7pp a +3pp), sugiriendo que inserción laboral es más duradera que transferencias

**Hipótesis**: Transferencias monetarias tienen efecto inmediato pero temporal; activación laboral tiene efecto más duradero.

### Evaluación de eficiencia: Análisis costo-efectividad

**Costo anual por familia**: $1,200,000

**Efecto**: Reducción de pobreza extrema de 16 puntos porcentuales

**Costo por familia que sale de pobreza extrema**:

```
$1,200,000 / 0.16 = $7,500,000 por familia
```

**Comparación con alternativas**:

| Programa | Costo por familia sacada de pobreza |
|----------|--------------------------------------|
| Ingreso Ético Familiar | $7,500,000 |
| Programa Puente (2002-2011) | $5,200,000 |
| Transferencias monetarias puras (sin acompañamiento) | $3,800,000 |

**Hallazgo**: IEF es menos costo-efectivo que programas anteriores. Explicación: Componente de acompañamiento psicosocial es costoso y tiene efectos limitados en pobreza monetaria.

### Debate sobre el programa

**Defensores del IEF**:
- Enfoque multidimensional aborda pobreza de manera integral
- Incentivos laborales (Bono Trabajo Mujer) promueven autonomía vs dependencia de transferencias
- Efectos van más allá de ingresos (acceso a servicios, organización familiar)

**Críticos del IEF**:
- Baja costo-efectividad comparado con transferencias simples
- Acompañamiento psicosocial tiene efectos limitados y es costoso
- Condicionalidades laborales pueden excluir a mujeres sin acceso a empleo (rurales, con hijos pequeños)

**Lecciones de la evaluación**:
1. **Sinergias limitadas**: Componentes múltiples no generaron efectos superiores a suma de partes (contrario a hipótesis de sinergia)
2. **Incentivos laborales funcionan**: Bono Trabajo Mujer efectivamente aumentó empleo femenino
3. **Sostenibilidad requiere empleo**: Efectos más duraderos vienen de inserción laboral, no de transferencias

### Legado y evolución del programa

**Reemplazo por Ingreso Familiar de Emergencia (2020)**:
- Gobierno de Sebastián Piñera (2018-2022) reemplazó IEF por nuevo programa
- Mantiene transferencias monetarias pero elimina acompañamiento psicosocial (por baja efectividad)
- Focalización más estricta en extrema pobreza

**Evidencia influyó en diseño**: Evaluación mostró que componentes de mayor impacto eran transferencias + incentivos laborales, no acompañamiento.

## Lecciones transversales de los tres casos

### Sobre diseño evaluativo

1. **Aprovechar variación no experimental**: Los tres casos usaron cuasi-experimentos (DiD, PSM) ante imposibilidad de RCT
2. **Evaluaciones tempranas y continuas**: Evaluaciones de procesos permitieron ajustes antes de evaluación de impacto
3. **Métodos mixtos**: Combinación cuanti-cuali explica no solo "cuánto" sino "cómo" y "por qué"

### Sobre uso de evidencia

1. **Rediseños informados**: Las tres evaluaciones llevaron a modificaciones de programas (ChCC amplió componentes, SEP mejoró acompañamiento, IEF simplificó estructura)
2. **Transparencia de limitaciones**: Evaluaciones reconocen limitaciones metodológicas (sesgo de selección potencial, efectos de largo plazo no medidos)
3. **Diálogo con política**: Evidencia no determina decisiones, pero informa debate público

### Sobre desafíos metodológicos recurrentes

1. **Atribución causal en programas universales**: ChCC y SEP requirieron aprovechar rollout gradual
2. **Heterogeneidad territorial**: Los tres programas muestran gran variabilidad en efectividad según territorio
3. **Efectos de largo plazo**: Evaluaciones midieron efectos 1-3 años; impactos finales (trayectorias de vida) requieren décadas

## Ejercicio práctico: Diseño de evaluación

Considere el **Programa de Apoyo a la Retención Escolar** (en liceos vulnerables) que incluye:

- Tutorías académicas personalizadas
- Apoyo psicosocial (psicólogos en liceos)
- Becas de manutención ($50,000/mes)
- Talleres de habilidades socioemocionales

**Tarea**: Diseñe una evaluación de impacto para este programa respondiendo:

1. **Pregunta evaluativa principal** y 2 preguntas secundarias
2. **Indicadores de resultado** (al menos 3, incluyendo retención y aprendizajes)
3. **Diseño metodológico**: ¿RCT, DiD, PSM u otro? Justifique según factibilidad
4. **Datos necesarios**: Fuentes de información y periodicidad de mediciones
5. **Análisis de heterogeneidad**: ¿Para qué subgrupos esperaría efectos diferenciales?
6. **Cronograma**: Timing de línea base, implementación y seguimiento

## Referencias

### Chile Crece Contigo

Staab, S., & Gerhard, R. (2010). *Childcare service expansion in Chile and Mexico: For women or children or both?* UNRISD.

Ministerio de Desarrollo Social (2016). *Evaluación de impacto del programa Chile Crece Contigo en el desarrollo infantil*. Santiago.

### Subvención Escolar Preferencial

Mizala, A., & Torche, F. (2012). *Bringing the schools back in: The stratification of educational achievement in the Chilean voucher system*. International Journal of Educational Development, 32(1), 132-144.

Correa, J. A., Parro, F., & Reyes, L. (2014). *The effects of vouchers on school results: Evidence from Chile's targeted voucher program*. Documento de Trabajo CLAPES UC.

### Ingreso Ético Familiar

Martínez, C., & Perticará, M. (2017). *Childcare effects on maternal employment: Evidence from Chile*. Journal of Development Economics, 126, 127-137.

DIPRES (2016). *Informe final de evaluación Programa Ingreso Ético Familiar*. Ministerio de Hacienda, Chile.

### Generales sobre evaluación en Chile

DIPRES (2020). *Sistema de Evaluación y Control de Gestión: 30 años de evaluación de programas públicos en Chile*. Ministerio de Hacienda.

Beyer, H., & Vergara, R. (2019). *¿Qué hacer con Chile? Ensayos sobre desarrollo y política pública*. Ediciones Universidad Diego Portales.
