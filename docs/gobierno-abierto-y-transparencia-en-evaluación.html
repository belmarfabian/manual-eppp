<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 4 Gobierno abierto y transparencia en evaluación | Evaluación de Políticas Públicas</title>
  <meta name="description" content="Manual de evaluación de políticas públicas para estudiantes de Administración Pública" />
  <meta name="generator" content="bookdown 0.45 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 4 Gobierno abierto y transparencia en evaluación | Evaluación de Políticas Públicas" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Manual de evaluación de políticas públicas para estudiantes de Administración Pública" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 4 Gobierno abierto y transparencia en evaluación | Evaluación de Políticas Públicas" />
  
  <meta name="twitter:description" content="Manual de evaluación de políticas públicas para estudiantes de Administración Pública" />
  

<meta name="author" content="Fabián Belmar" />


<meta name="date" content="2025-11-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="marco-institucional-de-la-evaluación-en-chile.html"/>
<link rel="next" href="evaluación-de-diseño-de-políticas-y-programas.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Evaluación de Políticas Públicas</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="part"><span><b>I Fundamentos</b></span></li>
<li class="chapter" data-level="1" data-path="introducción-a-la-evaluación-de-políticas-públicas.html"><a href="introducción-a-la-evaluación-de-políticas-públicas.html"><i class="fa fa-check"></i><b>1</b> Introducción a la evaluación de políticas públicas</a></li>
<li class="chapter" data-level="2" data-path="enfoques-y-metodologías-de-evaluación.html"><a href="enfoques-y-metodologías-de-evaluación.html"><i class="fa fa-check"></i><b>2</b> Enfoques y metodologías de evaluación</a></li>
<li class="chapter" data-level="3" data-path="marco-institucional-de-la-evaluación-en-chile.html"><a href="marco-institucional-de-la-evaluación-en-chile.html"><i class="fa fa-check"></i><b>3</b> Marco institucional de la evaluación en Chile</a></li>
<li class="chapter" data-level="4" data-path="gobierno-abierto-y-transparencia-en-evaluación.html"><a href="gobierno-abierto-y-transparencia-en-evaluación.html"><i class="fa fa-check"></i><b>4</b> Gobierno abierto y transparencia en evaluación</a></li>
<li class="part"><span><b>II Herramientas de Diagnóstico y Diseño</b></span></li>
<li class="chapter" data-level="5" data-path="evaluación-de-diseño-de-políticas-y-programas.html"><a href="evaluación-de-diseño-de-políticas-y-programas.html"><i class="fa fa-check"></i><b>5</b> Evaluación de diseño de políticas y programas</a></li>
<li class="chapter" data-level="6" data-path="árbol-de-problemas-metodología-cepal.html"><a href="árbol-de-problemas-metodología-cepal.html"><i class="fa fa-check"></i><b>6</b> Árbol de problemas: metodología CEPAL</a></li>
<li class="chapter" data-level="7" data-path="marco-lógico-instrumento-de-diseño-y-evaluación.html"><a href="marco-lógico-instrumento-de-diseño-y-evaluación.html"><i class="fa fa-check"></i><b>7</b> Marco lógico: instrumento de diseño y evaluación</a></li>
<li class="chapter" data-level="8" data-path="indicadores-de-desempeño-y-líneas-base.html"><a href="indicadores-de-desempeño-y-líneas-base.html"><i class="fa fa-check"></i><b>8</b> Indicadores de desempeño y líneas base</a></li>
<li class="chapter" data-level="9" data-path="sistemas-de-seguimiento-y-monitoreo.html"><a href="sistemas-de-seguimiento-y-monitoreo.html"><i class="fa fa-check"></i><b>9</b> Sistemas de seguimiento y monitoreo</a></li>
<li class="part"><span><b>III Evaluación de Resultados e Impacto</b></span></li>
<li class="chapter" data-level="10" data-path="evaluación-de-procesos-y-gestión.html"><a href="evaluación-de-procesos-y-gestión.html"><i class="fa fa-check"></i><b>10</b> Evaluación de procesos y gestión</a></li>
<li class="chapter" data-level="11" data-path="evaluación-de-resultados-criterios-oecd-dac.html"><a href="evaluación-de-resultados-criterios-oecd-dac.html"><i class="fa fa-check"></i><b>11</b> Evaluación de resultados: Criterios OECD-DAC</a></li>
<li class="chapter" data-level="12" data-path="evaluación-de-impacto-fundamentos.html"><a href="evaluación-de-impacto-fundamentos.html"><i class="fa fa-check"></i><b>12</b> Evaluación de impacto: Fundamentos</a></li>
<li class="chapter" data-level="13" data-path="métodos-cuantitativos-de-evaluación.html"><a href="métodos-cuantitativos-de-evaluación.html"><i class="fa fa-check"></i><b>13</b> Métodos cuantitativos de evaluación</a></li>
<li class="chapter" data-level="14" data-path="análisis-de-efectos-estructurales-y-sinergias.html"><a href="análisis-de-efectos-estructurales-y-sinergias.html"><i class="fa fa-check"></i><b>14</b> Análisis de efectos estructurales y sinergias</a></li>
<li class="part"><span><b>IV Aplicaciones</b></span></li>
<li class="chapter" data-level="15" data-path="casos-de-evaluación-en-chile.html"><a href="casos-de-evaluación-en-chile.html"><i class="fa fa-check"></i><b>15</b> Casos de evaluación en Chile</a></li>
<li class="chapter" data-level="16" data-path="elaboración-de-informes-de-evaluación.html"><a href="elaboración-de-informes-de-evaluación.html"><i class="fa fa-check"></i><b>16</b> Elaboración de informes de evaluación</a></li>
<li class="chapter" data-level="17" data-path="ética-y-buenas-prácticas-en-evaluación.html"><a href="ética-y-buenas-prácticas-en-evaluación.html"><i class="fa fa-check"></i><b>17</b> Ética y buenas prácticas en evaluación</a></li>
<li class="chapter" data-level="" data-path="referencias-12.html"><a href="referencias-12.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Evaluación de Políticas Públicas</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gobierno-abierto-y-transparencia-en-evaluación" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Capítulo 4</span> Gobierno abierto y transparencia en evaluación<a href="gobierno-abierto-y-transparencia-en-evaluación.html#gobierno-abierto-y-transparencia-en-evaluaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="el-paradigma-de-gobierno-abierto" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> El paradigma de gobierno abierto<a href="gobierno-abierto-y-transparencia-en-evaluación.html#el-paradigma-de-gobierno-abierto" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El gobierno abierto constituye un modelo de gestión pública fundamentado en tres pilares interdependientes: transparencia, participación ciudadana y colaboración entre actores. Como señala el Banco Mundial (2010), este paradigma trasciende la simple apertura de información gubernamental para configurar una arquitectura relacional donde Estado y sociedad civil interactúan horizontalmente en la producción, implementación y evaluación de políticas públicas.</p>
<p>La transparencia implica acceso ciudadano a información gubernamental comprensible, oportuna y utilizable. No se reduce a disponibilidad formal de datos sino a inteligibilidad efectiva: información técnicamente accesible pero incomprensible para audiencias no especializadas no satisface estándares de transparencia sustantiva. La participación refiere a involucramiento activo de ciudadanos y organizaciones en procesos de diseño, implementación y evaluación de políticas, reconociendo que distintos actores poseen conocimientos complementarios sobre problemas públicos y efectividad de intervenciones. La colaboración establece que gobierno, sector privado, academia y sociedad civil pueden co-producir soluciones más efectivas que las generadas unilateralmente por el Estado.</p>
<p>Este modelo cobra especial relevancia para evaluación de políticas públicas. Como argumenta el informe CEP (2017) sobre modernización del Estado chileno, sistemas evaluativos transparentes, participativos y colaborativos generan simultáneamente mayor calidad técnica —al incorporar perspectivas diversas—, mayor legitimidad —al permitir escrutinio público— y mayor utilización de hallazgos —al generar apropiación entre actores que participaron en la evaluación.</p>
</div>
<div id="transparencia-evaluativa-en-chile-avances-y-limitaciones" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Transparencia evaluativa en Chile: avances y limitaciones<a href="gobierno-abierto-y-transparencia-en-evaluación.html#transparencia-evaluativa-en-chile-avances-y-limitaciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Chile destaca regionalmente por su transparencia evaluativa formal. Desde 1997, todas las evaluaciones del Programa de Evaluación de Programas Gubernamentales se publican íntegramente en el Portal de Evaluación y Control de Gestión de DIPRES (www.dipres.gob.cl). Esta apertura institucionalizada incluye informes finales completos, anexos metodológicos, bases de datos anonimizadas cuando aplicable, compromisos de implementación de recomendaciones y reportes de seguimiento de dichos compromisos.</p>
<p>El portal organiza evaluaciones por año, ministerio, tipo de evaluación y estado de implementación de recomendaciones. Usuarios pueden descargar libremente todos los documentos sin registro previo. Adicionalmente, DIPRES publica metodologías estándar, términos de referencia de licitaciones, y reportes anuales que sintetizan el ciclo evaluativo. Esta infraestructura de transparencia contrasta marcadamente con sistemas de otros países donde evaluaciones circulan como documentos internos de gobierno con acceso restringido a tomadores de decisión.</p>
<p>Sin embargo, accesibilidad formal no garantiza acceso efectivo. Como documenta Irarrázaval et al. (2020), la mayoría de evaluaciones DIPRES constituyen documentos técnicamente complejos, extensos (frecuentemente 100+ páginas) y redactados en lenguaje especializado que presupone familiaridad con metodologías evaluativas. Ciudadanos sin formación técnica, periodistas generalistas e incluso funcionarios públicos de áreas no especializadas enfrentan barreras significativas para interpretar y utilizar estos documentos.</p>
<p>La ausencia sistemática de resúmenes ejecutivos amigables —síntesis de 2-3 páginas en lenguaje accesible destacando hallazgos prioritarios y recomendaciones accionables— limita severamente la democratización efectiva del acceso a evidencia evaluativa. Mientras especialistas —académicos, consultores, analistas de think tanks— utilizan extensivamente el portal DIPRES, audiencias más amplias permanecen efectivamente excluidas del acceso a esta información pública.</p>
<p>El Banco Integrado de Programas Sociales (BIPS), administrado por el Ministerio de Desarrollo Social, complementa parcialmente el portal DIPRES al proporcionar información estandarizada sobre diseño, población objetivo, cobertura y presupuesto de programas sociales. Su interfaz más amigable y fichas sintéticas facilitan comparaciones entre programas. Sin embargo, el BIPS enfrenta limitaciones de actualización y completitud, con programas descritos de modo heterogéneo y datos frecuentemente desactualizados.</p>
</div>
<div id="participación-ciudadana-en-procesos-evaluativos" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Participación ciudadana en procesos evaluativos<a href="gobierno-abierto-y-transparencia-en-evaluación.html#participaci%C3%B3n-ciudadana-en-procesos-evaluativos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La participación puede operar en múltiples momentos del ciclo evaluativo con diferentes niveles de intensidad. Arnstein (1969) propone una escalera de participación que distingue entre: (1) información —comunicación unidireccional de decisiones ya tomadas—, (2) consulta —recopilación de opiniones sin compromiso vinculante de incorporarlas—, (3) participación colaborativa —influencia real en decisiones—, y (4) delegación —transferencia de poder decisional a ciudadanos. En evaluación de políticas, estas modalidades se traducen en prácticas diferenciadas.</p>
<p>En la <strong>definición de preguntas evaluativas</strong>, participación implica involucrar a beneficiarios, implementadores y otros stakeholders en identificar qué aspectos del programa resultan más críticos de examinar. Gestores pueden priorizar eficiencia operacional; beneficiarios, calidad de atención y pertinencia de prestaciones; implementadores de primera línea, viabilidad de procedimientos. Cada perspectiva enriquece el diseño evaluativo al revelar dimensiones que evaluadores externos podrían ignorar.</p>
<p>En <strong>recolección de datos</strong>, participación opera mediante entrevistas semi-estructuradas, grupos focales, talleres participativos o encuestas que capturan experiencias, valoraciones y recomendaciones de quienes interactúan cotidianamente con el programa. Métodos participativos como cartografía social, fotovoz o relatos de vida permiten que beneficiarios documenten sus experiencias en formatos no extractivos donde ellos controlan narrativas.</p>
<p>En <strong>interpretación de hallazgos</strong>, participación implica contrastar evidencia cuantitativa con conocimiento experiencial de implementadores y beneficiarios. Talleres de validación donde evaluadores presentan hallazgos preliminares y reciben retroalimentación permiten identificar interpretaciones erróneas, matizar conclusiones y generar recomendaciones más viables.</p>
<p>La literatura internacional documenta que evaluaciones participativas —cuando bien diseñadas— generan múltiples beneficios: mayor validez al incorporar conocimiento local que evaluadores externos carecen, mayor legitimidad al incluir voces de afectados, mayor utilización al generar apropiación de hallazgos entre actores que participaron, y empoderamiento de beneficiarios al reconocer su expertise sobre el programa.</p>
<p>El caso chileno muestra participación limitada y selectiva. Evaluaciones DIPRES típicamente se diseñan mediante negociación entre la División de Control de Gestión y los ministerios sectoriales responsables del programa evaluado, con involucramiento acotado incluso de gestores operacionales y prácticamente nulo de beneficiarios en la definición de preguntas evaluativas. Durante la recolección de datos, consultoras externas conducen entrevistas con directivos y funcionarios, y ocasionalmente grupos focales con beneficiarios, pero en modalidades extractivas donde ciudadanos proveen información sin participar en análisis o interpretación.</p>
<p>Este déficit participativo refleja tensiones estructurales del sistema chileno. La priorización de independencia técnica y rigor metodológico —valores centrales del modelo— genera recelos hacia participación que podría comprometer objetividad. El énfasis en evaluación como instrumento de fiscalización presupuestaria incentiva diseños tecnocráticos sobre enfoques participativos. Restricciones de tiempo y presupuesto limitan la viabilidad de procesos participativos genuinos que demandan inversión sostenida de recursos.</p>
</div>
<div id="uso-de-evaluaciones-por-organizaciones-de-la-sociedad-civil" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Uso de evaluaciones por organizaciones de la sociedad civil<a href="gobierno-abierto-y-transparencia-en-evaluación.html#uso-de-evaluaciones-por-organizaciones-de-la-sociedad-civil" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Más allá de acceso gubernamental a evaluaciones para decisiones presupuestarias, sistemas de gobierno abierto aspiran a que múltiples actores —organizaciones de la sociedad civil, medios de comunicación, academia, ciudadanos individuales— utilicen evidencia evaluativa para advocacy, escrutinio de políticas, investigación o periodismo. Esta diversificación de usuarios democratiza el sistema evaluativo y genera presión para uso efectivo de hallazgos por parte de gobierno.</p>
<p>En Chile, organizaciones especializadas —think tanks como Centro de Estudios Públicos, Fundación Sol, CIPER, Espacio Público— utilizan intensivamente evaluaciones DIPRES para análisis de políticas, reportes de investigación y columnas de opinión. Estas organizaciones cuentan con capacidades técnicas para interpretar metodologías complejas y extraer implicancias de política. Sus productos —policy briefs, estudios, artículos de prensa— traducen hallazgos técnicos a formatos más accesibles para audiencias amplias.</p>
<p>Académicos emplean evaluaciones gubernamentales como fuentes secundarias para investigación, contrastando hallazgos con estudios propios, replicando análisis con metodologías alternativas o utilizando datos públicos para nuevas preguntas de investigación. Este uso académico genera escrutinio de calidad técnica del sistema evaluativo, identifica limitaciones metodológicas y produce conocimiento que enriquece debates de política.</p>
<p>Medios de comunicación utilizan evaluaciones ocasionalmente, típicamente cuando hallazgos son políticamente controversiales (programas emblemáticos evaluados negativamente, casos de ineficiencia severa, denuncias de mala focalización). Sin embargo, cobertura mediática es episódica y frecuentemente superficial, reproduciendo titulares sin análisis profundo de metodologías o matices de hallazgos.</p>
<p>Organizaciones sectoriales —sindicatos de profesores, colegios profesionales, federaciones de funcionarios— utilizan selectivamente evaluaciones cuando hallazgos respaldan sus demandas. Esto genera uso estratégico donde actores citan evidencia favorable e ignoran hallazgos inconvenientes, fenómeno que refleja naturaleza política del uso de evidencia.</p>
<p>Ciudadanos individuales muestran uso marginal de evaluaciones, limitado a casos donde programas les afectan directamente y disponen de capital educacional para navegar documentos técnicos. Esta brecha de acceso efectivo sugiere que transparencia formal beneficia primariamente a élites técnicas y políticas, reproduciendo desigualdades epistémicas.</p>
</div>
<div id="estrategias-de-comunicación-de-hallazgos-evaluativos" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Estrategias de comunicación de hallazgos evaluativos<a href="gobierno-abierto-y-transparencia-en-evaluación.html#estrategias-de-comunicaci%C3%B3n-de-hallazgos-evaluativos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Comunicación efectiva de evaluaciones requiere reconocer que distintas audiencias necesitan diferentes productos con niveles de detalle, complejidad técnica y formato adaptados a sus usos previstos. Una evaluación comprehensiva debe generar múltiples productos comunicacionales, no un único informe técnico.</p>
<p><strong>Para tomadores de decisión políticos y directivos superiores</strong>: Resúmenes ejecutivos de 2-3 páginas que sinteticen hallazgos priorizados según relevancia para decisiones, expliciten implicancias de política con claridad, y presenten recomendaciones accionables jerarquizadas por urgencia e impacto potencial. Lenguaje debe ser directo, evitar jerga técnica innecesaria y privilegiar visualizaciones sobre tablas densas.</p>
<p><strong>Para gestores operacionales del programa evaluado</strong>: Informes detallados que profundicen en dimensiones operacionales —cuellos de botella específicos, variaciones territoriales de implementación, análisis de costos unitarios, comparaciones con benchmarks sectoriales— con recomendaciones concretas sobre ajustes de procedimientos, capacitación de personal o reasignación de recursos. Estos usuarios valoran granularidad sobre síntesis.</p>
<p><strong>Para ciudadanía general</strong>: Síntesis visuales de 1-2 páginas con infografías, gráficos simples y lenguaje completamente desprovisto de tecnicismos. Estos productos deben responder preguntas básicas: ¿El programa cumplió sus objetivos? ¿Los recursos se usaron bien? ¿Qué mejoras se proponen? Videos cortos o podcasts pueden complementar productos escritos para audiencias con preferencias por formatos audiovisuales.</p>
<p><strong>Para comunidad académica y técnica</strong>: Informes completos con anexos metodológicos exhaustivos, bases de datos, especificaciones de modelos estadísticos, discusión de limitaciones y comparación con literatura especializada. Estos usuarios priorizan rigor y replicabilidad sobre accesibilidad.</p>
<p><strong>Para medios de comunicación</strong>: Notas de prensa sintéticas que destaquen hallazgos noticiables, contextualicen con datos accesibles, incluyan citas atribuibles y proporcionen contactos para ampliar información. Kits de prensa con gráficos descargables facilitan cobertura.</p>
<p>Estrategias exitosas incluyen lanzamientos públicos de evaluaciones con presentaciones a múltiples audiencias, conferencias de prensa para evaluaciones de alto perfil, webinars para actores especializados, y repositorios digitales organizados temáticamente que faciliten búsqueda. Redes sociales institucionales pueden difundir hallazgos en formatos breves que dirijan a documentos completos.</p>
<p>El desafío radica en balancear transparencia comprehensiva —publicación de informes técnicos completos— con accesibilidad diferenciada —productos adaptados a audiencias diversas. Sistemas evaluativos maduros invierten recursos significativos en comunicación, reconociendo que evaluaciones técnicamente impecables pero no comunicadas efectivamente desperdician su potencial de mejora de políticas y rendición de cuentas.</p>
</div>
<div id="desafíos-de-implementación" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Desafíos de implementación<a href="gobierno-abierto-y-transparencia-en-evaluación.html#desaf%C3%ADos-de-implementaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La agenda de gobierno abierto en evaluación enfrenta obstáculos estructurales. Primero, tensiones entre independencia técnica y participación: evaluadores externos independientes maximizan credibilidad pero carecen de conocimiento contextual que implementadores y beneficiarios poseen; participación puede enriquecer comprensión pero genera riesgos de captura donde actores con intereses en el programa influencian sesgadamente hallazgos.</p>
<p>Segundo, restricciones de recursos y tiempo: procesos participativos genuinos demandan inversión sostenida en convocatoria, facilitación, devolución de resultados e incorporación efectiva de insumos. Evaluaciones con plazos ajustados y presupuestos limitados difícilmente pueden implementar participación robusta sin comprometer calidad técnica.</p>
<p>Tercero, capacidades diferenciadas de actores: participación efectiva requiere que ciudadanos y organizaciones cuenten con conocimientos mínimos sobre evaluación para contribuir constructivamente. Ausencia de capacidades genera participación ceremonial donde actores proveen opiniones desconectadas de evidencia o desconocimiento de trade-offs inevitables en política pública.</p>
<p>Cuarto, cultura organizacional resistente: instituciones públicas habituadas a operar opacamente enfrentan costos de transición hacia transparencia y rendición de cuentas. Funcionarios pueden percibir evaluaciones participativas como amenazas antes que oportunidades de mejora, generando resistencias que obstaculizan acceso a información o sesgan interacciones con evaluadores.</p>
</div>
<div id="preguntas-de-reflexión-3" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Preguntas de reflexión<a href="gobierno-abierto-y-transparencia-en-evaluación.html#preguntas-de-reflexi%C3%B3n-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Revise el portal DIPRES (www.dipres.gob.cl). Descargue una evaluación reciente. ¿Qué tan accesible encuentra el documento para un ciudadano sin formación en evaluación? ¿Qué elementos comunicacionales agregaría?</p></li>
<li><p>Considere el Programa Acompañamiento Psicosocial. ¿En qué momentos del ciclo evaluativo involucraría a familias beneficiarias? ¿Qué metodologías participativas emplearía sin comprometer rigor técnico?</p></li>
<li><p>Un think tank de oposición política utiliza selectivamente hallazgos de una evaluación gubernamental para criticar un programa emblemático del gobierno, ignorando matices metodológicos. ¿Cómo debería responder el evaluador? ¿Qué responsabilidades tiene sobre uso de sus hallazgos?</p></li>
<li><p>¿Qué ventajas y riesgos tiene que evaluaciones gubernamentales sean completamente públicas versus circulación restringida entre tomadores de decisión?</p></li>
</ol>
</div>
<div id="referencias-del-capítulo-3" class="section level2 hasAnchor" number="4.8">
<h2><span class="header-section-number">4.8</span> Referencias del capítulo<a href="gobierno-abierto-y-transparencia-en-evaluación.html#referencias-del-cap%C3%ADtulo-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Banco Mundial (2010). <em>La formulación de políticas en la OCDE: Ideas para América Latina</em>. Banco Mundial LAC.</li>
<li>CEP (2017). <em>Un Estado para la ciudadanía. Informe de la Comisión de Modernización del Estado</em>. Centro de Estudios Públicos.</li>
<li>Irarrázaval, I., Larrañaga, O., Rodríguez, J., &amp; Valdés, R. (2020). <em>Propuestas para una mejor calidad del gasto y las políticas públicas en Chile</em>. Centro de Políticas Públicas UC.</li>
<li>Pérez, G., &amp; Maldonado, C. (Eds.) (2015). <em>Panorama de los sistemas nacionales de monitoreo y evaluación en América Latina</em>. CIDE/Clear LAC.</li>
</ul>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="marco-institucional-de-la-evaluación-en-chile.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="evaluación-de-diseño-de-políticas-y-programas.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/YOUR_GITHUB_USERNAME/YOUR_BOOK_REPO/edit/master/04-gobierno-abierto.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["evaluacion_politicas_publicas.pdf", "evaluacion_politicas_publicas.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  },
  "toolbar": {
    "position": "fixed"
  }
});
});
</script>

</body>

</html>
