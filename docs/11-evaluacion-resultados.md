# Evaluación de resultados: Criterios OECD-DAC

La evaluación de resultados examina si un programa logró sus objetivos y generó los cambios esperados. A diferencia de la evaluación de procesos (que examina la implementación), la evaluación de resultados se enfoca en los **cambios efectivos** en beneficiarios y contexto.

## Los seis criterios OECD-DAC

El Comité de Ayuda al Desarrollo (DAC) de la OCDE desarrolló seis criterios estándar para evaluar programas de cooperación internacional. Estos criterios han sido adoptados ampliamente para evaluar políticas y programas públicos en general.

**Actualización 2019**: La OCDE actualizó los criterios separando **Pertinencia** de **Coherencia** como dimensiones independientes.

### 1. Pertinencia (Relevance)

**Pregunta central**: ¿Los objetivos del programa corresponden a las necesidades y prioridades reales de los beneficiarios y del contexto?

**Dimensiones a evaluar**:

- **Pertinencia ex-ante**: ¿El diseño del programa respondía a un problema real identificado mediante diagnóstico riguroso?
- **Pertinencia dinámica**: ¿El programa se adaptó a cambios en necesidades y contexto durante su implementación?
- **Pertinencia para beneficiarios**: ¿Los servicios/productos ofrecidos son valorados y útiles para los beneficiarios?
- **Alineamiento con prioridades**: ¿El programa está alineado con prioridades sectoriales, regionales y nacionales?

**Métodos de evaluación**:

1. **Análisis documental**: Revisión de diagnósticos sectoriales, estudios de línea base, documentos de diseño
2. **Comparación con brechas actuales**: Contraste entre problema que aborda el programa y situación actual del sector
3. **Consultas a beneficiarios**: Encuestas o grupos focales sobre pertinencia de servicios recibidos
4. **Consultas a expertos**: Entrevistas a especialistas del sector sobre prioridades actuales

**Ejemplo**: Un programa de alfabetización digital para adultos mayores diseñado en 2010 enfocado en uso de computadores de escritorio puede haber perdido pertinencia en 2020, cuando la necesidad crítica es uso de smartphones para acceso a servicios públicos y trámites en línea.

**Indicadores típicos**:
- % de beneficiarios que declaran que el programa responde a sus necesidades prioritarias
- Alineamiento entre objetivos del programa y brechas identificadas en diagnósticos sectoriales recientes
- Grado de ajuste del programa a cambios en el contexto (flexibilidad)

### 2. Coherencia (Coherence)

**Pregunta central**: ¿El programa es compatible con otras intervenciones similares y está alineado con políticas sectoriales?

**Dimensiones a evaluar**:

**Coherencia interna**: Consistencia entre objetivos, componentes y actividades del programa

**Coherencia externa**:
- **Complementariedad**: ¿El programa se complementa con otros programas para generar sinergias?
- **No duplicación**: ¿El programa evita duplicar esfuerzos de otras intervenciones?
- **Alineamiento sectorial**: ¿El programa es consistente con políticas sectoriales vigentes?
- **Articulación institucional**: ¿El programa coordina con otras instituciones relevantes?

**Métodos de evaluación**:

1. **Mapeo de intervenciones**: Identificar programas que operan en misma población/territorio/sector
2. **Análisis de complementariedades**: Evaluar si existen sinergias o duplicaciones con otros programas
3. **Revisión de políticas**: Verificar alineamiento con marcos normativos y estratégicos sectoriales
4. **Entrevistas institucionales**: Consultar a otras instituciones sobre coordinación y articulación

**Ejemplo**: Un programa municipal de apoyo a microemprendedores puede tener baja coherencia si duplica servicios de SERCOTEC (servicio nacional), en lugar de complementarse focalizando en segmentos no atendidos o especializándose en rubros específicos.

**Indicadores típicos**:
- Número de instancias formales de coordinación con programas similares
- % de beneficiarios que acceden simultáneamente a programas complementarios
- Nivel de alineamiento con políticas sectoriales (análisis documental)

### 3. Eficacia (Effectiveness)

**Pregunta central**: ¿El programa logró sus objetivos y metas comprometidas?

**Principio fundamental**: La eficacia se mide comparando **resultados esperados** (establecidos en diseño) con **resultados observados** (medidos en evaluación).

**Dimensiones a evaluar**:

- **Cumplimiento de metas cuantitativas**: ¿Se alcanzaron las metas numéricas de cobertura, productos y resultados?
- **Logro de objetivos cualitativos**: ¿Se produjeron los cambios esperados en beneficiarios?
- **Eficacia diferencial**: ¿La eficacia varía entre subgrupos, territorios o modalidades?
- **Contribución relativa**: Distinguir entre objetivos principales y secundarios

**Advertencia metodológica**: Un programa puede cumplir metas secundarias pero fracasar en su objetivo principal. La eficacia debe evaluarse priorizando objetivos según su importancia relativa.

**Métodos de evaluación**:

1. **Análisis de cumplimiento de metas**: Comparar indicadores de producto y resultado con metas comprometidas
2. **Encuestas a beneficiarios**: Medir cambios en variables de resultado (conocimientos, comportamientos, condiciones de vida)
3. **Análisis de heterogeneidad**: Identificar para quiénes el programa fue más o menos eficaz
4. **Comparación con línea base**: Medir cambio en indicadores desde situación inicial

**Ejemplo**: Programa de mejoramiento de viviendas con objetivo de mejorar condiciones habitacionales y reducir enfermedades respiratorias en niños.

- **Eficacia en objetivo primario** (salud): Reducción de 15% en enfermedades respiratorias (meta: 20%) → **Eficacia parcial**
- **Eficacia en objetivo secundario** (satisfacción): 85% de beneficiarios satisfechos con mejoras (meta: 70%) → **Meta superada**
- **Evaluación global**: Eficacia moderada, pues no alcanzó plenamente objetivo principal

**Indicadores típicos**:
- % de cumplimiento de metas de resultado comprometidas
- Cambio promedio en variables de resultado entre beneficiarios
- Diferencia entre línea base y línea de cierre en indicadores clave

### 4. Eficiencia (Efficiency)

**Pregunta central**: ¿Los resultados se lograron con un uso óptimo de recursos?

**Concepto**: La eficiencia relaciona **productos obtenidos** con **recursos utilizados**. Un programa es eficiente si maximiza resultados con recursos dados, o minimiza costos para lograr resultados deseados.

**Tipos de análisis de eficiencia**:

**1. Eficiencia productiva**: ¿Se minimizaron costos unitarios?

- Costo por beneficiario atendido
- Costo por unidad de producto entregado
- Comparación con estándares técnicos o programas similares

**2. Eficiencia asignativa**: ¿Los recursos se asignaron a usos que maximizan impacto?

- Distribución del presupuesto entre componentes
- Focalización de recursos en beneficiarios con mayor necesidad/potencial de cambio

**3. Eficiencia temporal**: ¿Los procesos operan sin demoras innecesarias?

- Tiempo desde postulación hasta recepción de beneficio
- Identificación de cuellos de botella

**Métodos de evaluación**:

1. **Análisis de costos unitarios**: Calcular costo por beneficiario, por producto, por resultado
2. **Benchmarking**: Comparar costos y productividad con programas similares (nacional o internacional)
3. **Análisis de procesos**: Identificar ineficiencias operacionales (duplicación, demoras, subutilización)
4. **Frontera de producción**: Estimar máximo producto alcanzable con recursos dados

**Ejemplo**: Programa de capacitación laboral

- **Costo por capacitado**: $500.000 por persona
- **Benchmark nacional**: Promedio de programas similares es $350.000
- **Hallazgo**: Programa tiene baja eficiencia productiva (40% más caro que promedio)
- **Explicación**: Alta proporción de costos administrativos (30% vs 15% estándar) y grupos pequeños (10 personas vs 20 óptimo)

**Indicadores típicos**:
- Costo unitario por beneficiario o producto
- Ratio costo administrativo / costo directo
- Ejecución presupuestaria (% de presupuesto ejecutado)
- Tiempo promedio de procesos críticos

**Herramientas avanzadas**:

- **Análisis Envolvente de Datos (DEA)**: Identifica unidades (territorios, establecimientos) más eficientes como referencia
- **Análisis costo-efectividad**: Costo por unidad de resultado logrado (ej: costo por estudiante que mejora rendimiento)

### 5. Impacto (Impact)

**Pregunta central**: ¿Qué efectos de largo plazo y de amplio alcance ha generado el programa, más allá de sus resultados inmediatos?

**Diferencia entre resultado e impacto**:

- **Resultado**: Cambio directo e inmediato en beneficiarios (ej: personas capacitadas)
- **Impacto**: Efecto de largo plazo, amplio y potencialmente indirecto (ej: reducción sostenida de pobreza en territorio)

**Dimensiones de impacto**:

1. **Impacto en beneficiarios directos**: Cambios sostenidos en condiciones de vida
2. **Impacto en no-beneficiarios**: Efectos indirectos (spillovers)
3. **Impacto territorial**: Cambios en comunidades o territorios completos
4. **Impacto sectorial**: Transformaciones en sectores de política pública

**Desafío central: Atribución causal**

Para afirmar que el programa causó el impacto, es necesario distinguir:
- **Efectos del programa** (atribuibles a la intervención)
- **Tendencias contextuales** (que habrían ocurrido de todos modos)
- **Otros factores** (cambios económicos, otras políticas)

**Métodos de evaluación de impacto**: Ver Capítulo 12 para desarrollo detallado de diseños experimentales y quasi-experimentales.

**Indicadores típicos**:
- Cambios en indicadores de bienestar de mediano/largo plazo (ingresos, salud, educación)
- Efectos en indicadores territoriales o sectoriales
- Persistencia de cambios 2-5 años post-intervención

### 6. Sostenibilidad (Sustainability)

**Pregunta central**: ¿Los beneficios del programa perdurarán después de que finalice la intervención?

**Dimensiones de sostenibilidad**:

**1. Sostenibilidad financiera**
- ¿Existen recursos comprometidos para continuar el programa o sus componentes?
- ¿Se fortalecieron capacidades de generación de recursos locales?

**2. Sostenibilidad institucional**
- ¿Se crearon estructuras organizacionales que perduran?
- ¿Se instalaron procedimientos y sistemas de gestión?
- ¿Hay apropiación institucional del programa?

**3. Sostenibilidad técnica**
- ¿Se desarrollaron capacidades técnicas locales?
- ¿Existen equipos formados que pueden continuar operando?
- ¿Se transfirió conocimiento y metodología?

**4. Sostenibilidad social**
- ¿Hay apropiación del programa por parte de beneficiarios y comunidad?
- ¿Se fortalecieron organizaciones comunitarias?
- ¿Hubo cambios en normas y prácticas sociales que persisten?

**5. Sostenibilidad ambiental** (cuando aplica)
- ¿Las intervenciones son ambientalmente sostenibles?
- ¿Se consideraron efectos ambientales de largo plazo?

**Métodos de evaluación**:

1. **Seguimiento post-programa**: Medir si beneficios se mantienen 1-3 años después del cierre
2. **Análisis institucional**: Evaluar apropiación y capacidades instaladas
3. **Análisis financiero**: Revisar compromisos presupuestarios futuros
4. **Consultas a actores**: Entrevistas sobre expectativas de continuidad

**Ejemplo**: Programa de fortalecimiento de centros comunitarios

- **Alta sostenibilidad social**: Organizaciones comunitarias apropiadas de gestión de centros
- **Baja sostenibilidad financiera**: Municipio no comprometió presupuesto para mantención
- **Evaluación**: Riesgo de deterioro de infraestructura a pesar de apropiación social

**Indicadores típicos**:
- % de componentes del programa que continúan operando post-cierre
- Presupuesto comprometido para continuidad
- Número de personal capacitado que permanece en funciones
- Nivel de apropiación comunitaria/institucional (escala)

## Aplicación práctica de criterios OECD-DAC

La evaluación de resultados usando criterios OECD-DAC requiere operacionalizar cada criterio mediante:

### Matriz de evaluación

| Criterio | Pregunta evaluativa | Indicadores | Fuentes de evidencia | Métodos |
|----------|---------------------|-------------|----------------------|---------|
| Pertinencia | ¿El programa responde a necesidades actuales? | - % beneficiarios que valoran pertinencia<br>- Alineamiento con diagnósticos | - Encuesta beneficiarios<br>- Análisis documental | - Survey<br>- Análisis comparativo |
| Coherencia | ¿El programa se complementa con otros? | - Número de programas complementarios<br>- Nivel coordinación | - Entrevistas institucionales<br>- Mapeo programas | - Análisis de redes<br>- Entrevistas |
| Eficacia | ¿Se cumplieron objetivos? | - % cumplimiento metas<br>- Cambio en variables resultado | - Registros programa<br>- Encuesta beneficiarios | - Análisis estadístico<br>- Pre-post |
| Eficiencia | ¿Se optimizaron recursos? | - Costo unitario<br>- Benchmark | - Ejecución presupuestaria<br>- Estudios comparativos | - Análisis costos<br>- Benchmarking |
| Impacto | ¿Efectos de largo plazo? | - Cambios sostenidos bienestar<br>- Efectos atribuibles | - Datos panel<br>- Grupo control | - Quasi-experimento<br>- DiD |
| Sostenibilidad | ¿Beneficios perduran? | - Componentes que continúan<br>- Apropiación local | - Seguimiento post<br>- Entrevistas | - Estudios longitudinales<br>- Análisis institucional |

## Caso: Aplicación de criterios OECD-DAC al Programa de Acompañamiento y Acceso Efectivo (PACE)

El Programa PACE (desde 2014) busca restablecer igualdad de oportunidades en acceso a educación superior de estudiantes de establecimientos educacionales vulnerables mediante preparación académica y acceso garantizado a universidades.

### Evaluación por criterios

**1. PERTINENCIA: ALTA**

- **Evidencia**: Chile presenta alta segregación educacional. Solo 15% de estudiantes de liceos vulnerables accede a educación superior (vs 60% de liceos privados)
- **Hallazgo**: PACE responde a brecha real y prioritaria en política educacional
- **Indicador**: 89% de estudiantes PACE declaran que preparación recibida fue pertinente para sus necesidades (Encuesta 2018)

**2. COHERENCIA: MEDIA-ALTA**

- **Interna**: Componentes (preparación académica + cupos garantizados) son coherentes y complementarios
- **Externa**: Se articula con Beca Nuevo Milenio y Gratuidad universitaria (complementariedad), pero genera tensión con sistema de admisión PSU/PDT (coherencia parcial)
- **Evidencia**: 45% de estudiantes PACE acceden a otros beneficios complementarios (becas, gratuidad)

**3. EFICACIA: MEDIA**

- **Meta de acceso**: 70% de beneficiarios que completan preparación acceden a educación superior
- **Resultado observado**: 55% accede (79% de cumplimiento de meta)
- **Meta de titulación**: 50% de ingresados se titula en tiempo esperado
- **Resultado observado**: 32% se titula (64% de cumplimiento)
- **Hallazgo**: Eficacia parcial. Logra aumentar acceso pero enfrenta desafíos en retención y titulación

**4. EFICIENCIA: MEDIA-BAJA**

- **Costo por beneficiario**: $1.200.000 anual por estudiante en preparación
- **Benchmark**: Programas similares de nivelación pre-universitaria cuestan $600.000-$800.000
- **Hallazgo**: Costos elevados explicados por acompañamiento integral y acceso garantizado, pero existen ineficiencias en gestión territorial (duplicación de talleres, subutilización de cupos)
- **Costo-efectividad**: $3.750.000 por estudiante que accede a educación superior

**5. IMPACTO: MEDIO (en evaluación)**

- **Impacto en beneficiarios**: Estudiantes PACE tienen 25 puntos porcentuales más de probabilidad de acceder a ES que similares no-PACE (estudio cuasi-experimental 2019)
- **Impacto territorial**: Liceos PACE aumentaron matrícula en enseñanza media (efecto reputacional)
- **Limitación**: Faltan estudios de impacto en largo plazo (ingresos, movilidad social)

**6. SOSTENIBILIDAD: MEDIA**

- **Financiera**: Programa institucionalizado con presupuesto permanente (alta)
- **Institucional**: 29 universidades participantes han creado unidades especializadas (alta)
- **Técnica**: Liceos han incorporado metodologías de acompañamiento a prácticas regulares (media)
- **Riesgo**: Dependencia de financiamiento estatal; universidades no comprometen recursos propios (sostenibilidad financiera vulnerable a cambios de prioridades)

### Síntesis evaluativa PACE

| Criterio | Valoración | Fortalezas | Debilidades |
|----------|------------|------------|-------------|
| Pertinencia | Alta | Responde a brecha prioritaria | - |
| Coherencia | Media-Alta | Buena articulación con becas | Tensión con sistema admisión |
| Eficacia | Media | Aumenta acceso significativamente | Baja titulación oportuna |
| Eficiencia | Media-Baja | Acompañamiento integral | Costos elevados, ineficiencias territoriales |
| Impacto | Medio | Efecto causal demostrado en acceso | Falta evidencia largo plazo |
| Sostenibilidad | Media | Institucionalización en universidades | Dependencia fiscal |

**Recomendaciones derivadas**:

1. **Eficiencia**: Estandarizar gestión territorial para reducir duplicaciones y optimizar costos
2. **Eficacia**: Fortalecer acompañamiento en educación superior (no solo en acceso) para mejorar retención
3. **Sostenibilidad**: Incentivar cofinanciamiento de universidades participantes

## Ejercicio práctico

Considere un programa municipal de rehabilitación de espacios públicos (plazas, parques) en barrios vulnerables que operó durante 3 años con los siguientes componentes:

- Mejoramiento de infraestructura (juegos infantiles, bancas, áreas verdes)
- Talleres de apropiación comunitaria (formación de comités vecinales)
- Capacitación en mantención para dirigentes

**Datos disponibles**:
- Presupuesto ejecutado: $800 millones para 15 plazas
- 2,500 familias beneficiadas directamente
- 78% de satisfacción de usuarios
- 12 comités vecinales creados (de 15 plazas)
- Programa concluyó hace 1 año; 8 plazas mantienen buenas condiciones

**Tarea**: Evalúe el programa aplicando los 6 criterios OECD-DAC:

Para cada criterio:
1. Formule una pregunta evaluativa específica
2. Identifique qué información adicional necesitaría recolectar
3. Proponga al menos un indicador cuantitativo
4. Emita un juicio evaluativo preliminar (alto/medio/bajo) basado en datos disponibles

**Ejemplo para Pertinencia**:
- Pregunta: ¿La rehabilitación de plazas respondía a necesidades prioritarias de las comunidades?
- Información adicional necesaria: Diagnóstico participativo pre-intervención, ranking de prioridades vecinales
- Indicador: % de beneficiarios que declaran que mejoramiento de espacios públicos era necesidad prioritaria
- Juicio preliminar: Medio (falta evidencia de diagnóstico participativo)

Complete el análisis para los otros 5 criterios.

## Referencias

OECD-DAC (2019). *Better Criteria for Better Evaluation: Revised Evaluation Criteria Definitions and Principles for Use*. OECD Publishing.

DIPRES (2017). *Guías metodológicas para la evaluación ex-post de programas sociales*. Ministerio de Hacienda, Chile.

Gertler, P. J., Martinez, S., Premand, P., Rawlings, L. B., & Vermeersch, C. M. (2016). *Impact evaluation in practice* (2nd ed.). World Bank.

Rossi, P. H., Lipsey, M. W., & Henry, G. T. (2019). *Evaluation: A systematic approach* (8th ed.). Sage Publications.

CEPAL (2015). *Manual de formulación y evaluación de proyectos sociales*. Santiago de Chile.
